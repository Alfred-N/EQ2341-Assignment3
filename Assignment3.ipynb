{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Assignment3.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApuTUcAIi9ro",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620311622566,
     "user_tz": -120,
     "elapsed": 1130,
     "user": {
      "displayName": "Alfred Nilsson",
      "photoUrl": "",
      "userId": "03565282794176820890"
     }
    },
    "outputId": "5e831649-f265-459c-b845-569d8bbbfb6f"
   },
   "source": [
    "from PattRecClasses.GaussD import GaussD\n",
    "from PattRecClasses.MarkovChain import MarkovChain\n",
    "from PattRecClasses.HMM import HMM\n",
    "from PattRecClasses.DiscreteD import DiscreteD"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/root\n",
      "/content/drive/MyDrive/Teknisk fysik /ML-master/EQ2341 Pattern Recognition and Machine Learning/Assignment_3\n",
      "Assignment3.ipynb  \u001B[0m\u001B[01;34mFigures\u001B[0m/  gauss_logprob.py  \u001B[01;34mPattRecClasses\u001B[0m/  \u001B[01;34mSongs\u001B[0m/\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LoyRPdElcx0a"
   },
   "source": [
    "import numpy as np\n",
    "'''\n",
    "frIsequence = GetMusicFeatures(signal,fs)\n",
    "or\n",
    "frIsequence = GetMusicFeatures(signal,fs,winlength)\n",
    "\n",
    "Method to calculate features for melody recognition\n",
    "\n",
    "Usage:\n",
    "First load a sound file using wavfile.read(...) or similar, then use this function\n",
    "to extract pitch and energy contours of the melody in the sound. This\n",
    "information can be used to compute a sequence of feature values or\n",
    "vectors for melody recognition. Note that the pitch estimation is\n",
    "unreliable (typically giving very high values) in silent segments, and\n",
    "may not work at all for polyphonic sounds.\n",
    "\n",
    "Input:\n",
    "signal=      Vector containing sampled signal values (must be mono).\n",
    "fs=          Sampling frequency of signal in Hz.\n",
    "winlength=   Length of the analysis window in seconds (default 0.03).\n",
    "             Square (\"boxcar\") analysis windows with 50% overlap are used.\n",
    "\n",
    "Output:\n",
    "frIsequence= Matrix containing pitch, correlation, and intensity estimates\n",
    "             for use in creating features for melody recognition. Each column\n",
    "             represents one frame in the analysis. Elements in the first\n",
    "             row are pitch estimates in Hz (80--1100 Hz), the second row\n",
    "             estimates the correlation coefficient (rho) between adjacent\n",
    "             pitch periods, while the third row contains corresponding\n",
    "             estimates of per-sample intensity.\n",
    "\n",
    "References:\n",
    "This method is based on a pitch estimator provided by Obada Alhaj Moussa.\n",
    "'''\n",
    "\n",
    "def GetMusicFeatures(signal, fs, winlength=0.03):\n",
    "\n",
    "    # Wikipedia: \"human voices are roughly in the range of 80 Hz to 1100 Hz\"\n",
    "    minpitch = 80\n",
    "    maxpitch = 1100\n",
    "\n",
    "    signal = np.real(np.double(signal)) # Make sure the signal is a real double\n",
    "\n",
    "    signal = signal - np.mean(signal) # Remove DC, which can disturb intesities\n",
    "\n",
    "    if fs <= 0:\n",
    "        fs = samplerate # Replace illegal fs-values with the read sampling freq.\n",
    "\n",
    "    # Compute the pitch periods in samples for the human voice range\n",
    "    minlag = int( np.round(fs/maxpitch) )\n",
    "    maxlag = int( np.round(fs/minpitch) )\n",
    "\n",
    "    winlength = np.abs(winlength)\n",
    "    winlength = np.round(winlength*fs) # Convert to number of samples\n",
    "    winlength = max([ winlength+(winlength % 2), 2*minlag ]) # Make windows sufficiently long and an even sample number\n",
    "\n",
    "    winstep = int( winlength/2 );\n",
    "    nsteps = int( np.floor(len(signal)/winstep) ) - 1\n",
    "\n",
    "    if (nsteps < 1):\n",
    "        print(['ERROR: Signal too short. Use at least %s samples!'%(str(winlength))])\n",
    "        return None\n",
    "\n",
    "    frIsequence = np.zeros((3,nsteps)) # Initialize output variable to correct size\n",
    "\n",
    "    pprdList = []\n",
    "    for n in range(nsteps):\n",
    "        # Cut out a segment of the signal starting at offset n*winlength sec\n",
    "        window = signal[n*winstep : (n+1)*winstep]\n",
    "\n",
    "        # Estimate the pitch (sampling frequency/pitch period), between-period\n",
    "        # correlation coefficient, and intensity\n",
    "        pprd, maxcorr = yin_pitch(window,minlag,maxlag)\n",
    "        frIsequence[:,n] = [fs/pprd, maxcorr, np.linalg.norm(window/np.sqrt(len(window)))]\n",
    "        pprdList.append(pprd)\n",
    "        \n",
    "    return frIsequence,pprdList\n",
    "\n",
    "'''\n",
    "Below is the pitch period estimation sub-routine.\n",
    "The estimate is based on the autocorrelation function.\n",
    "'''\n",
    "def yin_pitch(signal,minlag=40,maxlag=200):\n",
    "\n",
    "    N = len(signal)\n",
    "    \n",
    "    dif = np.zeros(maxlag - minlag)\n",
    "    for idx in range(minlag, maxlag):\n",
    "        seg1 = signal[idx : ]\n",
    "        seg2 = signal[ : N - idx]\n",
    "\n",
    "        # Estimate correlation (\"dif\") at lag idx\n",
    "        dif[idx - minlag] = sum((seg1 - seg2)**2) / (N - idx)\n",
    "\n",
    "    thresh = (max(dif) - min(dif)) * 0.1 + min(dif);\n",
    "\n",
    "    \n",
    "    # Locate the first minimum of dif, which is the first maximum of the\n",
    "    # correlation; the corresponding lag is the pitch period.\n",
    "    pprd = None\n",
    "    idx = minlag\n",
    "    while ( idx < maxlag ):\n",
    "        if dif[idx - minlag] <= thresh:\n",
    "            pprd = idx\n",
    "            break\n",
    "\n",
    "        idx = idx + 1\n",
    "\n",
    "    # Allow the procedure to find the first minimum to roll over small \"bumps\"\n",
    "    # in the autocorrelation functions, that are below than a 10% threshold.\n",
    "    while idx < maxlag:\n",
    "        if dif[idx - minlag] >= thresh:\n",
    "            break\n",
    "\n",
    "        if dif[idx - minlag] < dif[pprd - minlag]:\n",
    "            pprd = idx\n",
    "\n",
    "        idx = idx + 1\n",
    "\n",
    "    seg1 = signal[pprd : ]\n",
    "    seg2 = signal[: N - pprd]\n",
    "\n",
    "    maxcorr = np.corrcoef(seg1,seg2)[0,1]\n",
    "    \n",
    "    return (pprd, maxcorr)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "nfVrIWzJmkzx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620311629403,
     "user_tz": -120,
     "elapsed": 7950,
     "user": {
      "displayName": "Alfred Nilsson",
      "photoUrl": "",
      "userId": "03565282794176820890"
     }
    },
    "outputId": "60aba414-88b4-4496-8e9a-1379426e6c6e"
   },
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "%ls\n",
    "fileName = \"melody_1\"\n",
    "sr, mel1 = wavfile.read(\"Songs/\"+fileName +  \".wav\")\n",
    "\n",
    "frIsequence,pprd =  GetMusicFeatures(mel1, sr, winlength=0.03)\n",
    "\n",
    "#frIsequence[0][150:200] =  frIsequence[0][150:200] * 2\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(frIsequence[0,:])\n",
    "plt.title(\"Frequency\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.xlabel(\"t\")\n",
    "#plt.savefig(\"Figures/freq_\" + str(fileName) + \".png\")\n",
    "\n",
    "# plt.plot(frIsequence[1,:])\n",
    "# plt.title(\"corr\")\n",
    "# plt.ylabel(\"r\")\n",
    "# plt.xlabel(\"t\")\n"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'show_config' from 'numpy' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-f8253d28e1ef>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwavfile\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mwavfile\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ls'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m''\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mfileName\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"melody_1\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0msr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmel1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwavfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Songs/\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mfileName\u001B[0m \u001B[1;33m+\u001B[0m  \u001B[1;34m\".wav\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alfred\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[0m__all__\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'test'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mshow_config\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mshow_numpy_config\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mshow_numpy_config\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m     raise ImportError(\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'show_config' from 'numpy' (unknown location)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJvo34ziw7KJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620311629404,
     "user_tz": -120,
     "elapsed": 7939,
     "user": {
      "displayName": "Alfred Nilsson",
      "photoUrl": "",
      "userId": "03565282794176820890"
     }
    },
    "outputId": "f842fdde-c5ae-427c-8271-ad06961d6339"
   },
   "source": [
    "def GetSemitones(frIsequence):\n",
    "  f_log = np.log(frIsequence[0])\n",
    "  f = frIsequence[0]\n",
    "  mean = np.mean(f_log)\n",
    "  stdev = np.std(f_log)\n",
    "  f_max = mean + stdev\n",
    "  f_min = mean - stdev\n",
    "\n",
    "  log_I = np.log(frIsequence[2])\n",
    "  r_thresh = np.mean(frIsequence[1])\n",
    "  I_thresh = np.mean(log_I)\n",
    "\n",
    "  r = frIsequence[1]\n",
    "\n",
    "  noise = np.zeros(np.shape(f))\n",
    "  print(noise.shape)\n",
    "  for i in range(len(f)):\n",
    "    if f_log[i]>f_max or f_log[i]<f_min or (r[i]<r_thresh and log_I[i]<I_thresh):\n",
    "      noise[i] = 1\n",
    "  #f_clean = f_log[np.where(noise==0)]\n",
    "  f_clean = f[np.where(noise==0)]\n",
    "  base_freq=np.min(f_clean)\n",
    "  print(base_freq)\n",
    "  semitones = 12*np.log2(f/base_freq) + 1\n",
    "\n",
    "  for i in range(len(noise)):\n",
    "    if noise[i] ==1:\n",
    "      semitones[i] = np.random.rand(1)*0.5\n",
    "  return semitones\n",
    "semi1 = GetSemitones(frIsequence)\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.plot(semi1)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "(498,)\n",
      "114.24870466321244\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWi8dSok-tPf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620312029590,
     "user_tz": -120,
     "elapsed": 561,
     "user": {
      "displayName": "Alfred Nilsson",
      "photoUrl": "",
      "userId": "03565282794176820890"
     }
    },
    "outputId": "50996135-5bc7-48fb-d99f-9d05dae7ec07"
   },
   "source": [
    "'''\n",
    "logP = gauss_logprob(pDs,x)\n",
    "method to give the probability of a data sequence,\n",
    "assumed to be drawn from given Gaussian Distribution(s).\n",
    "\n",
    "Input:\n",
    "pD=    GaussD object or array of GaussD objects\n",
    "x=     row vector with data assumed to be drawn from a Gaussian Distribution\n",
    "\n",
    "Result:\n",
    "logP=  array with log-probability values for each element in x,\n",
    "       for each given GaussD object\n",
    "       size(p)== [length(pDs),size(x,2)], if pDs is one-dimensional vector\n",
    "       size(p)== [size(pDs),size(x,2)], if pDs is multidim array\n",
    "'''\n",
    "def gauss_logprob(pDs, x):\n",
    "    nObj = len(pDs) # Number of GaussD Objects\n",
    "    nx = x.shape[1] # Number of observed vectors\n",
    "    logP = np.zeros((nObj, nx))\n",
    "\n",
    "    for i, pD in enumerate(pDs):\n",
    "        dSize = pD.dataSize\n",
    "        assert dSize == x.shape[0]\n",
    "\n",
    "        z = np.dot(pD.covEigen, (x-np.matlib.repmat(pD.means, 1, nx)))\n",
    "\n",
    "        z /= np.matlib.repmat(np.expand_dims(pD.stdevs, 1), 1, nx)\n",
    "\n",
    "        logP[i, :] = -np.sum(z*z, axis=0)/2 \n",
    "        logP[i, :] = logP[i, :] - sum(np.log(pD.stdevs)) - dSize*np.log(2*np.pi)/2\n",
    "\n",
    "    return logP\n",
    "\n",
    "\n",
    "## TESTCASES\n",
    "\n",
    "#One-dimensional Gaussian\n",
    "# g = []\n",
    "# nsemitones=12\n",
    "# for i in range(nsemitones):\n",
    "#   g.append(GaussD( means=np.array( [i] ) , stdevs=np.array( [1.0] ) ))\n",
    "\n",
    "\n",
    "g1 = GaussD( means=np.array( [0] ) , stdevs=np.array( [1.0] ) )\n",
    "g2 = GaussD( means=np.array( [3] ) , stdevs=np.array( [2.0] ) )\n",
    "g=[g1,g2]\n",
    "x_Seq = np.array([[-0.2, 2.6, 1.3]])\n",
    "logP = gauss_logprob(g,x_Seq)\n",
    "\n",
    "print(np.exp(logP))\n",
    "print(sum(sum(np.exp(logP))))\n",
    "\n",
    "mc = MarkovChain( np.array( [[ 1, 0]] ), np.array( [ [ 0.9, 0.1], [ 0.1, 0.9 ] ] ) ) \n",
    "#mc = MarkovChain( np.array( [[ 1, 0]] ), np.array( [ [ 0.9, 0.1, 0], [ 0, 0.9, 0.1 ] ] ) ) \n",
    "# T = len(logP[0,:]) \n",
    "# N= len(logP) #num states\n",
    "# print (T)\n",
    "# print(N)\n",
    "\n",
    "alpha = mc.forward(logP)\n",
    "\n",
    "print(alpha)\n",
    "\n",
    "\n",
    "# nsemitones=12\n",
    "# means = np.array([np.arange(1,nsemitones + 1,dtype=float)]).transpose()\n",
    "# cov = np.eye(nsemitones)\n",
    "# # # Multi-dimensional Gaussian\n",
    "# g1 = GaussD( means=means , cov=cov)\n",
    "# # g1.rand(2)\n",
    "\n",
    "# print([cov[0],cov[1]])\n",
    "\n",
    "# gauss_logprob([g1], x_Seq)\n",
    "\n",
    "# # Output: array([[-1.86376038, -2.74915905, -2.73003471]])\n",
    "\n",
    "# # # Mismatched Parameters\n",
    "# # g2 = GaussD( means=np.array( [[3.0], [0.0]] ) , cov=np.array( [[1.0, 0.5], [0.5, 1.0]] ) )\n",
    "# # gauss_logprob([g2], g1.rand(3))\n",
    "\n",
    "# # Output: array([[-11.66457869,  -3.23578104,  -4.46681203]])"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0.9659684626499029\n",
      "[[-0.93893853  3.63279514 -5.79425568]\n",
      " [-0.          0.15324282 -0.98903201]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRJAUshRmaGy"
   },
   "source": [
    "Your assignment report should include:\n",
    "\n",
    "• Plots of the pitch and intensity profiles of the three recordings from\n",
    "Songs.zip, two from the same melody, and one from another song.\n",
    "MatLab code files for these plots should also be included. Make sure\n",
    "that the scales and units are correct, and show which curve corresponds\n",
    "to which recording.\n",
    "\n",
    "• A clear specification of the design of your feature extractor, how it\n",
    "integrates with the PattRecClasses output distributions, and how\n",
    "your scheme addresses each of the requirements listed previously. It\n",
    "must be clear that you understand your extractor and why it works.\n",
    "• Working MatLab code for your feature extractor, either attached as\n",
    "one or more separate m-files, or in a zip archive.\n",
    "\n",
    "• Plots illustrating how your extracted features behave over time for the\n",
    "three example files. It should be clear that two of the series are quite\n",
    "similar, whereas the third is significantly different. Again, code for\n",
    "generating these plots should be included.\n",
    "\n",
    "• A plot that compares your feature output between a melody with a\n",
    "transposed pitch track and the original recording, showing equivalence,\n",
    "along with code for generating the plot.\n",
    "\n",
    "• A discussion of aspects not captured by your feature extraction sys\u0002tem, and possible cases where your feature extraction scheme may\n",
    "work poorly. Is there any way a human can confuse the system, and\n",
    "perform a melody or create a sound signal that we think sounds similar\n",
    "to another performance, but where the features produced by your func\u0002tion are quite different between the two performances? What about\n",
    "the opposite situation—can we create two recordings that sound like\n",
    "two different songs altogether, but which actually generate very similar\n",
    "feature sequences?"
   ]
  }
 ]
}